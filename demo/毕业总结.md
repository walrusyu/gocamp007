# 毕业总结
## 1. go runtime
### 1.1 GPM模型
#### G（goroutine）
通过go func()创建，一个goroutine的栈内存消耗为2KB，理论上没有创建限制
#### M（machine）
所有M都有线程栈，一个M对应一个线程，如果不对该线程栈提供内存的话，系统会给该线程栈提供内存
#### P（Processor）
负责将G调度到M上运行，理论上一个P对应一个CPU，可以通过$GOMAXPROCS环境变量设定
#### 对比GM模型的优势
GM模型：多个M从一个全局的P队列获取可用的P并运行，这个全局的P队列锁竞争导致性能损耗
GPM模型：P本身维护一个G队列，如果这个队列为空，则从全局的G队列拉去一半的G，这样做的好处时降低了全局锁的争用
### 1.2 内存模型
#### 1.2.1 一般内存模型
##### page
内存管理的基本单元，大小为8K
##### span
一个或多个连续的page组成一个span
##### sizeclass
每个span都带有一个sizeclass，每一种sizeclass都对应一种object大小
##### object
将span按照object大小分割成等大的object
#### 1.2.2 Go内存管理模型
##### 小于32kb内存分配
###### mspan
Go内存管理的基本单元
###### mcache
每个P持有一系列不同规格的mspan，从8b到32kb不等，每次分配内存时，都会去大于等于所需容量的规格mspan中去找合适的空闲内存
###### mcentral
为mcache提供切分好的mspan资源，mcache中没有合适的mspan时，就会去mcentral中找，由于mcentral是全局共享的，所以申请资源需要加锁
###### mheap
mcentral没有空闲的mspan时，会向mheap申请，mheap没有资源时，会向操作系统申请新内存，mheap 主要用于大对象的内存分配
###### arena
mheap 里的 arena 区域是真正的堆区，运行时会将8kb看做一页，这些内存页中存储了所有在堆上初始化的对象
##### 小于16b内存分配
划分为tiny对象，被放入class为2的span（16b）中
##### 大于16b内存分配
从mheap上分配对应的数量的内存页
### 1.2.3 gc原理
#### 引用计数
记录每一个对象的引用次数，可能导致循环引用等问题
#### 追踪式垃圾回收
#### Mark&Sweep
步骤：
1. Stop the World
2. Mark：通过Root和Root直接间接访问到的对象，寻找所有可达的对象，并进行标记
3. Sweep：所有未标记的对象加入freelist， 可用于再分配
4. Start the World

问题：GC 执行期间需要把整个程序完全暂停
#### Tri-color Mark（三色标记法）
• 白色对象：潜在的垃圾，其内存可能会被垃圾收集器回收
• 灰色对象 ：活跃的对象，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象
• 黑色对象：活跃的对象，包括不存在任何引用外部指针的对象以及从根对象可达的对象，垃圾回收器不会扫描这些对象的子对象。

# 2. 微服务
## 2.1 微服务设计
### Api Gateway
整合横跨切面的功能（路由、认证、限流、安全等）
### BFF(Backend For Frontend)
集成各业务模块，提供统一的业务接口
### Microservice
具体各个不同的业务模块
## 2.2 grpc
内部的各服务之间（api gateway，bff，microservice）通过grpc通信，提高通信效率
### grpc优势
1. 充分利用http2.0的特性，提高通信效率
2. 多语言支持，通过工具自动生成服务端与客户端代码
## 2.3 服务发现
### 客户端服务发现
客户端维护自己的服务注册表，请求时通过本地的负载均衡算法找到合适的服务端
### 服务端服务发现
服务器端维护服务注册表，将客户端的请求，通过负载均衡算法，路由到合适的服务实例，可能会有中心化的问题
## 2.4 服务注册
1. Provider注册后定期发送心跳，服务端长时间收不到服务的心跳，则下线该服务（若短时间内有大量心跳丢失，则开启自我保护，延迟过期服务的删除）
2. Consumer启动后拉取服务注册表

## 2.5 多集群
提高性能和冗余能力，同时也存在cache hit ratio下降的问题
## 2.6 多租户
隔离不同的租户信息，可用户做灰度发布（通过标记，将部分流量导入待测试的服务）

# 3. Error
Go中的err不会导致程序停止，需要通过代码去针对不同的err进行处理
## 3.1 Error Type
### Sentinel Error
预设的错误类型，需要通过"=="比对error与预设的error
### ErrorTypes
通过包装error，提供更多的上下文信息
### Opaque errors
包装error，不返回特定的error value，而是断言某个特性，比如MyError.IsTimeout()等等
### errors.Is()&errors.As()
errors.Is()：判断是否是某个错误
errors.As()：将错误转化为特定错误

# 4. 可用性设计
## 4.1 隔离
### 服务隔离
动静分离：动态api与静态资源分离，针对动态与静态的资源进行不同的处理</br>
读写分离：主从结构，CQRS</br>
### 轻重隔离
核心隔离：将业务按照level进行划分，根据不同的业务等级，分配不同的资源</br>
快慢隔离：将快慢服务分离，避免慢服务影响快服务</br>
热点隔离：对热点数据分配单独的资源</br>
### 物理隔离
线程隔离</br>
进程隔离</br>
集群隔离</br>
## 4.2 超时控制
使用context.Deadline()或者context.Timeout()控制服务的整体响应时间，以打到fast fail的目的
## 4.3 过载保护
1. 通过漏桶/令牌桶算法，达到阻止或者减少进入流量的目的，桶的阈值很难合理设定
2. 通过利特尔法则，计算峰值时的流量
3. 通过一个独立的线程，以滑动窗口的形式去计算当前的负载，并通过一定的算法，生成最新的阈值配置并分发给不同的服务
## 4.4 熔断限流
1. 令牌桶/漏桶，针对单个节点，无法分布式限流
2. QPS限流，标准无法节点，不同的服务可能QPS的阈值不同
3. 对用户进行限流
4. 按照优先级丢弃

分布式限流：针对不同的服务，分配不同的quota，Max-Min Fairness，按重要程度，拒绝低优先级的请求</br>
熔断：服务级别的熔断，用户级别的熔断，依据都是资源配额的使用

## 4.5 降级
降级本质为: 提供有损服务
1. UI 模块化，非核心模块降级
2. BFF 层聚合 API，模块降级
3. 页面上一次缓存副本
4. 默认值、热门推荐等
5. 流量拦截 + 定期数据缓存(过期副本策略)
## 4.6 重试
重试会导致流量的放大，所以在在调用某个服务出现错误时，进行有限次数的重试
如果重试的服务下游还有一大堆服务，流量放大会很严重
重试必须保证幂等性
## 4.7 负载均衡
通过不同的负载均衡算法分发请求
## 4.8 最佳实践
* 变更管理:70％的问题是由变更引起的，恢复可用代码并不总是坏事
* 避免过载:过载保护、流量调度等
* 依赖管理:任何依赖都可能故障，做 chaos monkey testing，注入故障测试
* 优雅降级:有损服务，避免核心链路依赖故障
* 重试退避:退让算法，冻结时间，API retry detail 控制策略
* 超时控制:进程内 + 服务间超时控制
* 极限压测 + 故障演练
* 扩容 + 重启 + 消除有害流量

# 5. 架构设计
* 中间件解耦
* 缓存加速
* 分库分表
* Singleflight归并回源

# 6. 分布式缓存&事务
## 6.1 缓存选型
### Memcache
* 简单的kv存储，多线程，吞吐量大，value不能超过1MB
* 以slab方式做内存管理，每个slab包含若干个大小为1MB的内存页
* 每个内存页被分割成多个chunk，每个chunk存储一个item
### Redis
* 数据类型丰富
* 单线程，效率高
* 6.0引入多线程
* 多个I/O线程负责指令读取解析客户端指令，以及回写数据
* 指令的执行还是单线程
* cluster的slot机制，每个节点负责一批slot
## 6.2 分布式事务
* 本地事务的执行
* 二阶段提交（执行事务但不提交->提交事务）
* 三阶段提交（确认各客户端是否能进行事务->执行事务但不提交->提交事务）
* TCC(try->confirm->cancel)
* 分布式事务必须保证每一个操作都是幂等的
# 7. 网络编程
## http/1.1
* 增加了持久连接，每个请求进行串行请求
* 浏览器为每个域名最多同时维护 6 个 TCP 持久连接
* 使用CDN的实现域名分片机制
## HTTP/2
* 请求数据二进制分帧层处理之后，会转换成请求 ID 编号的帧，通过协议栈将这些帧发送给服务器
* 服务器接收到所有帧之后，会将所有相同 ID 的帧合并为一条完整的请求信息
* 然后服务器处理该条请求，并将处理的响应行、响应头和响应体分别发送至二进制分帧层
* 同样，二进制分帧层会将这些响应数据转换为一个个带有请求 ID编号的帧，经过协议栈发送给浏览器
* 浏览器接收到响应帧之后，会根据 ID 编号将帧的数据提交给对应的请求
## TLS/1.2
* 防窃听（eavesdropping），对应加密（Confidentiality）
* 防篡改（tampering），对应完整性校验（Integrity）
* 防伪造（forgery），对应认证过程（Authentication）
## TLS/1.3
通过Diffie–Hellman（DH）交换密钥
## I/O多路复用
### select
监听能力有限 — 最多只能监听 1024 个文件描述符</br>
内存拷贝开销大 — 需要维护一个较大的数据结构存储文件描述符，该结构需要拷贝到内核中</br>
时间复杂度O(n) — 返回准备就绪的事件个数后，需要遍历所有的文件描述符</br>
进程阻塞于 select，等待多个 I/O中的任一个变为可读，select 调用返回，通知相应 I/O 可以读</br>
它可以支持单线程响应多个请求这种模式</br>
### poll
时间复杂度O(n) — poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的
### epoll
时间复杂度O(1) — epoll可以理解为event poll，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是事件驱动（每个事件关联上fd）的，此时我们对这些流的操作都是有意义的。
### 唯一ID设计
#### Snowflake
1bit 不用</br>
41bit 时间戳</br>
10bit 机器ID</br>
12bit 序列号</br>
# 8. 日志&指标&链路追踪
## 8.1 ELK
### Elasticsearch
Elasticsearch 将数据以分片的形式压缩存储并提供多种 API 供用户查询、操作
### Logstach
采集数据
### Kibana
数据展示
### Kafka
采集到的数据先入Kafka
## 8.2 链路追踪
OpenTelemetry
### 常用Middleware方式

`type Middleware func(Handler) Handler`</br>
```
func Chain(h []*Middleware) *Middleware {
    return func(next Handler) Handler {
        for i := len(m) - 1; i >= 0; i-- {
            next = m[i](next)
        }
    return next
}
```
# 9. DNS&CDN&多活架构
## 9.1 DNS（Domain Name System）
### 递归查询
如果主机所询问的本地域名服务器不知道被查询域名的 IP 地址，那么本地域名服务器就以 DNS 客户的身份，向其他根域名服务器继续发出查询请求报文，而不是让该主机自己进行下一步的查询
### 迭代查询
当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的 IP 地址，要么告诉本地域名服务器：你下一步应当向哪一个域名服务器进行查询。然后让本地域名服务器进行后续的查询，而不是替本地域名服务器进行后续的查询
### DNS问题
* 域名劫持到其他域名
* 域名缓存</br>
* 运营商LocalDNS的解析转发（运营商自身不进行域名递归解析，而是把域名解析请求转发到其它运营商的递归 DNS 上的行为）</br>
### 高可用DNS
#### 自建HTTPDNS
通过 IP 直接请求 HTTP 获取服务器 A 记录地址，不存在向本地运营商询问domain 解析过程，所以从根本避免了劫持问题
## 9.2 CDN
### 缓存代理
通过智能 DNS 的筛选，用户的请求被透明地指向离他最近的省内骨干节点，最大限度地缩短用户信息的传输距离
### 路由加速
利用接入节点和中继节点或者多线节点互联互通
### 安全保护
无论面对的是渗透还是 DDoS 攻击，攻击的目标大都会被指向到了 CDN，进而保护了用户源站
### 节省成本
CDN 节点机房只需要在当地运营商的单线机房，或者带宽相对便宜的城市，采购成本低
### 内容路由
DNS 系统、应用层重定向，传输层重定向
### 内容分发
* PUSH：主动分发，内容管理系统发起，将内容从源分发到 CDN 的 Cache 节点，实时性高，但是受限于客户端的数据接受能力
* PULL：被动分发技术，用户请求驱动，用户请求内容中 miss，从源中或者其他 CDN 节点中实时获取内容，实时性低，客户端可自行决定何时拉取源数据
### 内容存储
随机读、顺序写、小文件的分布式存储
### 内容管理
提高内容服务的效率，提高 CDN 的缓存利用率
## 9.3 多活系统
### 业务分级
按照一定的标准将业务进行分级，挑选出核心的业务，只为核心业务核心场景设计异地多活，降低方案整体复杂度和实现成本
### 数据分类
挑选出核心业务后，需要对核心业务相关的数据进一步分析，目的在于识别所有的数据及数据特征，这些数据特征会影响后面的方案设计
### 数据同步
确定数据的特点后，我们可以根据不同的数据设计不同的同步方案
### 异常处理
无论数据同步方案如何设计，总是可能会出现异常情况，例如同步延迟、数据丢失、数据不一致等
### 多活系统可用的保证唯一性的方法
通过固定步长生成ID
# 10. 消息队列
## Kafka
* 以时间复杂度为 O(1) 的方式提供消息持久化能力即使对 TB 级以上数据也能保证常数时间复杂度的访问性能
* 高吞吐率，即使在非常廉价的商用机器上也能做到单机支持每秒 100K 条以上消息的传输
* 支持 Kafka Server 间的消息分区，及分布式消费，同时保证每个 Partition 内的消息顺序传输
* 同时支持离线数据处理和实时数据处理
* Scale out：支持在线水平扩展
## 消息系统的目的
* 削峰填谷，提高灵活性
* 可恢复性，消息队列数据支持持久化
* 顺序保证
* 异步通信，解耦系统
## Kafka结构
### Broker
Kafka集群的每个节点是一个Broker
### Topic
代表消息类型
### Partition
每个Topic被分成多个Partition，被分散在多个Broker上</br>
当 Partition 数量多于 Broker时，性能可能下降</br>
### Producer
消息生产者
### Consumer
消息消费者
### Consumer Group
group内的consumer消费一个或者多个partition
## 存储原理
顺序存储</br>
每个customer都会维护一个offset，代表读取到队列的哪个位置
## Replication
同一个Partition可以配置多个Replica，即一主多从
### Leader
负责与consumer交互
### Controller
所有的Broker中选出一个Controller，并负责所有Partition Leader的选举
### 数据一致性
* Raft
* pacificA
* BookKeeper


